{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Convolve Epoch 2- Problem Statement 3: Sentiment Analysis\n",
        "\n",
        "We are focussing on problem statement 3 which involves sentiment analysis of customer feedback of Cisco products to identify negative and positive reviews\n",
        "\n",
        "We are using an open-source library, Flair, for this. It gives us high accuracy and F1 score."
      ],
      "metadata": {
        "id": "U7d550DE3DFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, download datasets, pre-process datasets"
      ],
      "metadata": {
        "id": "U7pgKkxjFCtR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39mPCaoAtsdw"
      },
      "outputs": [],
      "source": [
        "# install Flair library\n",
        "!pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLAUVEF5tsdq"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "\n",
        "#Pandas, NumPy for data handling\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "#PyTorch for optimizers, schedulers\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim import AdamW\n",
        "\n",
        "#Flair for the pre-trained model and trainer\n",
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.embeddings import DocumentRNNEmbeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.visual.training_curves import Plotter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvPnfgoDEjtt"
      },
      "outputs": [],
      "source": [
        "# make a directory for training and testing data\n",
        "\n",
        "!mkdir /content/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the training and testing data\n",
        "\n",
        "!gdown 1VmpeZgh9reH3dUYRUlaqQsj2mh3hhdb- -O /content/data/PS3_train.xlsx\n",
        "!gdown 1S-_MQQGbBg18OAIawUk7zuIZg62dTy88 -O /content/data/PS3_test.xlsx"
      ],
      "metadata": {
        "id": "TNkXtopuKEb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reorganize the dataset, convert to .csv format required for Flair module\n",
        "\n",
        "review_df_train = pd.DataFrame(pd.read_excel(\"/content/data/PS3_train.xlsx\"))\n",
        "review_df_train.rename(columns={\"Verbatim Feedback \":\"text\", \"Sentiment (1=Positive & 0= Negative)\":\"label\"}, inplace=True)\n",
        "review_df_train.to_csv(\"/content/data/train.csv\", index=False, header=True)\n",
        "\n",
        "review_df_test = pd.DataFrame(pd.read_excel(\"/content/data/PS3_test.xlsx\"))\n",
        "review_df_test.to_csv(\"/content/data/test.csv\", index=False, header=True)"
      ],
      "metadata": {
        "id": "ztwvyrJf5mPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the unnecessary .xlsx files\n",
        "\n",
        "!rm /content/data/PS3_train.xlsx\n",
        "!rm /content/data/PS3_test.xlsx"
      ],
      "metadata": {
        "id": "zBNqqgm_RE0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model and training it"
      ],
      "metadata": {
        "id": "C4PtJwBYE6N4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "te1SV9ZhbUbr",
        "outputId": "67d82db3-3f4c-49f0-9440-55344c4b1a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:07,971 Reading data from /content/data\n",
            "2023-01-02 06:16:07,973 Train: /content/data/train.csv\n",
            "2023-01-02 06:16:07,975 Dev: None\n",
            "2023-01-02 06:16:07,978 Test: /content/data/test.csv\n",
            "2023-01-02 06:16:07,982 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "348it [00:00, 6174.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:08,045 Dictionary created for label 'class' with 3 values: negative (seen 195 times), positive (seen 153 times)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:14,684 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:14,690 Model: \"TextClassifier(\n",
            "  (decoder): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            "  (locked_dropout): LockedDropout(p=0.0)\n",
            "  (word_dropout): WordDropout(p=0.0)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): TransformerWordEmbeddings(\n",
            "        (model): RobertaModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): RobertaEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): RobertaLayer(\n",
            "                (attention): RobertaAttention(\n",
            "                  (self): RobertaSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): RobertaSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): RobertaIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (intermediate_act_fn): GELUActivation()\n",
            "                )\n",
            "                (output): RobertaOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): RobertaPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=768, out_features=256, bias=True)\n",
            "    (rnn): LSTM(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2023-01-02 06:16:14,693 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:14,699 Corpus: \"Corpus: 348 train + 39 dev + 0 test sentences\"\n",
            "2023-01-02 06:16:14,701 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:14,707 Parameters:\n",
            "2023-01-02 06:16:14,709  - learning_rate: \"0.000001\"\n",
            "2023-01-02 06:16:14,710  - mini_batch_size: \"32\"\n",
            "2023-01-02 06:16:14,712  - patience: \"3\"\n",
            "2023-01-02 06:16:14,714  - anneal_factor: \"0.5\"\n",
            "2023-01-02 06:16:14,722  - max_epochs: \"30\"\n",
            "2023-01-02 06:16:14,724  - shuffle: \"True\"\n",
            "2023-01-02 06:16:14,728  - train_with_dev: \"False\"\n",
            "2023-01-02 06:16:14,730  - batch_growth_annealing: \"False\"\n",
            "2023-01-02 06:16:14,735 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:14,736 Model training base path: \"resources/taggers/sentiment\"\n",
            "2023-01-02 06:16:14,737 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:14,750 Device: cuda:0\n",
            "2023-01-02 06:16:14,754 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:14,755 Embeddings storage mode: cpu\n",
            "2023-01-02 06:16:14,758 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/flair/trainers/trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:15,041 epoch 1 - iter 1/11 - loss 0.02989540 - samples/sec: 117.45 - lr: 0.000001\n",
            "2023-01-02 06:16:15,305 epoch 1 - iter 2/11 - loss 0.02969615 - samples/sec: 125.13 - lr: 0.000001\n",
            "2023-01-02 06:16:15,527 epoch 1 - iter 3/11 - loss 0.02929514 - samples/sec: 149.61 - lr: 0.000001\n",
            "2023-01-02 06:16:15,710 epoch 1 - iter 4/11 - loss 0.02929746 - samples/sec: 182.80 - lr: 0.000001\n",
            "2023-01-02 06:16:15,989 epoch 1 - iter 5/11 - loss 0.02885064 - samples/sec: 118.85 - lr: 0.000001\n",
            "2023-01-02 06:16:16,619 epoch 1 - iter 6/11 - loss 0.02898752 - samples/sec: 51.56 - lr: 0.000001\n",
            "2023-01-02 06:16:16,868 epoch 1 - iter 7/11 - loss 0.02904564 - samples/sec: 132.67 - lr: 0.000001\n",
            "2023-01-02 06:16:17,076 epoch 1 - iter 8/11 - loss 0.02932338 - samples/sec: 160.64 - lr: 0.000001\n",
            "2023-01-02 06:16:17,290 epoch 1 - iter 9/11 - loss 0.02944657 - samples/sec: 155.76 - lr: 0.000001\n",
            "2023-01-02 06:16:17,532 epoch 1 - iter 10/11 - loss 0.02935009 - samples/sec: 136.61 - lr: 0.000001\n",
            "2023-01-02 06:16:17,733 epoch 1 - iter 11/11 - loss 0.02972338 - samples/sec: 164.59 - lr: 0.000001\n",
            "2023-01-02 06:16:17,736 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:17,739 EPOCH 1 done: loss 0.0297 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:17,836 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:17,849 DEV : loss 0.04265611618757248 - f1-score (micro avg)  0.6667\n",
            "2023-01-02 06:16:17,859 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:17,860 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:19,543 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:20,146 epoch 2 - iter 1/11 - loss 0.02831015 - samples/sec: 106.54 - lr: 0.000001\n",
            "2023-01-02 06:16:20,361 epoch 2 - iter 2/11 - loss 0.02807632 - samples/sec: 154.32 - lr: 0.000001\n",
            "2023-01-02 06:16:20,986 epoch 2 - iter 3/11 - loss 0.02828354 - samples/sec: 51.96 - lr: 0.000001\n",
            "2023-01-02 06:16:21,230 epoch 2 - iter 4/11 - loss 0.02787862 - samples/sec: 136.05 - lr: 0.000001\n",
            "2023-01-02 06:16:21,448 epoch 2 - iter 5/11 - loss 0.02795342 - samples/sec: 152.26 - lr: 0.000001\n",
            "2023-01-02 06:16:21,674 epoch 2 - iter 6/11 - loss 0.02787904 - samples/sec: 147.10 - lr: 0.000001\n",
            "2023-01-02 06:16:21,893 epoch 2 - iter 7/11 - loss 0.02789049 - samples/sec: 151.28 - lr: 0.000001\n",
            "2023-01-02 06:16:22,132 epoch 2 - iter 8/11 - loss 0.02758701 - samples/sec: 138.43 - lr: 0.000001\n",
            "2023-01-02 06:16:22,390 epoch 2 - iter 9/11 - loss 0.02734447 - samples/sec: 127.80 - lr: 0.000001\n",
            "2023-01-02 06:16:22,640 epoch 2 - iter 10/11 - loss 0.02732750 - samples/sec: 132.45 - lr: 0.000001\n",
            "2023-01-02 06:16:22,871 epoch 2 - iter 11/11 - loss 0.02760730 - samples/sec: 143.74 - lr: 0.000001\n",
            "2023-01-02 06:16:22,874 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:22,877 EPOCH 2 done: loss 0.0276 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 21.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:22,983 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:22,994 DEV : loss 0.04026276245713234 - f1-score (micro avg)  0.7179\n",
            "2023-01-02 06:16:23,004 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:23,006 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:24,825 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:25,173 epoch 3 - iter 1/11 - loss 0.02522106 - samples/sec: 94.92 - lr: 0.000001\n",
            "2023-01-02 06:16:25,372 epoch 3 - iter 2/11 - loss 0.02578511 - samples/sec: 167.54 - lr: 0.000001\n",
            "2023-01-02 06:16:25,636 epoch 3 - iter 3/11 - loss 0.02536031 - samples/sec: 125.68 - lr: 0.000001\n",
            "2023-01-02 06:16:25,886 epoch 3 - iter 4/11 - loss 0.02536229 - samples/sec: 132.07 - lr: 0.000001\n",
            "2023-01-02 06:16:26,101 epoch 3 - iter 5/11 - loss 0.02536777 - samples/sec: 154.84 - lr: 0.000001\n",
            "2023-01-02 06:16:26,339 epoch 3 - iter 6/11 - loss 0.02553632 - samples/sec: 139.05 - lr: 0.000001\n",
            "2023-01-02 06:16:26,565 epoch 3 - iter 7/11 - loss 0.02576692 - samples/sec: 146.91 - lr: 0.000001\n",
            "2023-01-02 06:16:27,195 epoch 3 - iter 8/11 - loss 0.02585119 - samples/sec: 51.58 - lr: 0.000001\n",
            "2023-01-02 06:16:27,440 epoch 3 - iter 9/11 - loss 0.02586881 - samples/sec: 135.74 - lr: 0.000001\n",
            "2023-01-02 06:16:27,689 epoch 3 - iter 10/11 - loss 0.02598319 - samples/sec: 131.95 - lr: 0.000001\n",
            "2023-01-02 06:16:27,894 epoch 3 - iter 11/11 - loss 0.02620755 - samples/sec: 163.74 - lr: 0.000001\n",
            "2023-01-02 06:16:27,897 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:27,900 EPOCH 3 done: loss 0.0262 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:27,998 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:28,008 DEV : loss 0.038067568093538284 - f1-score (micro avg)  0.7692\n",
            "2023-01-02 06:16:28,016 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:28,018 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:29,729 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:30,005 epoch 4 - iter 1/11 - loss 0.02495911 - samples/sec: 120.67 - lr: 0.000001\n",
            "2023-01-02 06:16:30,259 epoch 4 - iter 2/11 - loss 0.02491671 - samples/sec: 131.05 - lr: 0.000001\n",
            "2023-01-02 06:16:30,475 epoch 4 - iter 3/11 - loss 0.02482638 - samples/sec: 154.74 - lr: 0.000001\n",
            "2023-01-02 06:16:31,107 epoch 4 - iter 4/11 - loss 0.02443052 - samples/sec: 51.36 - lr: 0.000001\n",
            "2023-01-02 06:16:31,390 epoch 4 - iter 5/11 - loss 0.02501586 - samples/sec: 117.15 - lr: 0.000001\n",
            "2023-01-02 06:16:31,596 epoch 4 - iter 6/11 - loss 0.02492087 - samples/sec: 161.67 - lr: 0.000001\n",
            "2023-01-02 06:16:31,781 epoch 4 - iter 7/11 - loss 0.02506259 - samples/sec: 178.60 - lr: 0.000001\n",
            "2023-01-02 06:16:32,003 epoch 4 - iter 8/11 - loss 0.02482518 - samples/sec: 150.33 - lr: 0.000001\n",
            "2023-01-02 06:16:32,208 epoch 4 - iter 9/11 - loss 0.02470889 - samples/sec: 162.83 - lr: 0.000001\n",
            "2023-01-02 06:16:32,432 epoch 4 - iter 10/11 - loss 0.02454676 - samples/sec: 148.60 - lr: 0.000001\n",
            "2023-01-02 06:16:32,652 epoch 4 - iter 11/11 - loss 0.02492665 - samples/sec: 150.08 - lr: 0.000001\n",
            "2023-01-02 06:16:32,655 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:32,658 EPOCH 4 done: loss 0.0249 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 24.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:32,749 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:32,760 DEV : loss 0.03599303588271141 - f1-score (micro avg)  0.7949\n",
            "2023-01-02 06:16:32,770 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:32,772 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:34,478 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:34,745 epoch 5 - iter 1/11 - loss 0.02986105 - samples/sec: 124.25 - lr: 0.000001\n",
            "2023-01-02 06:16:34,975 epoch 5 - iter 2/11 - loss 0.02743720 - samples/sec: 144.47 - lr: 0.000001\n",
            "2023-01-02 06:16:35,210 epoch 5 - iter 3/11 - loss 0.02565178 - samples/sec: 142.27 - lr: 0.000001\n",
            "2023-01-02 06:16:35,456 epoch 5 - iter 4/11 - loss 0.02478469 - samples/sec: 134.26 - lr: 0.000001\n",
            "2023-01-02 06:16:35,670 epoch 5 - iter 5/11 - loss 0.02479580 - samples/sec: 156.01 - lr: 0.000001\n",
            "2023-01-02 06:16:35,939 epoch 5 - iter 6/11 - loss 0.02471541 - samples/sec: 122.43 - lr: 0.000001\n",
            "2023-01-02 06:16:36,192 epoch 5 - iter 7/11 - loss 0.02475263 - samples/sec: 130.93 - lr: 0.000001\n",
            "2023-01-02 06:16:36,422 epoch 5 - iter 8/11 - loss 0.02485074 - samples/sec: 144.32 - lr: 0.000001\n",
            "2023-01-02 06:16:37,075 epoch 5 - iter 9/11 - loss 0.02479595 - samples/sec: 49.79 - lr: 0.000001\n",
            "2023-01-02 06:16:37,303 epoch 5 - iter 10/11 - loss 0.02452764 - samples/sec: 145.95 - lr: 0.000001\n",
            "2023-01-02 06:16:37,456 epoch 5 - iter 11/11 - loss 0.02476408 - samples/sec: 220.32 - lr: 0.000001\n",
            "2023-01-02 06:16:37,459 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:37,462 EPOCH 5 done: loss 0.0248 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 24.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:37,555 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:37,566 DEV : loss 0.03392515331506729 - f1-score (micro avg)  0.8718\n",
            "2023-01-02 06:16:37,575 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:37,576 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:39,323 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:39,641 epoch 6 - iter 1/11 - loss 0.02498012 - samples/sec: 104.84 - lr: 0.000001\n",
            "2023-01-02 06:16:40,301 epoch 6 - iter 2/11 - loss 0.02347327 - samples/sec: 49.26 - lr: 0.000001\n",
            "2023-01-02 06:16:40,471 epoch 6 - iter 3/11 - loss 0.02386504 - samples/sec: 197.37 - lr: 0.000001\n",
            "2023-01-02 06:16:40,673 epoch 6 - iter 4/11 - loss 0.02381759 - samples/sec: 164.90 - lr: 0.000001\n",
            "2023-01-02 06:16:40,881 epoch 6 - iter 5/11 - loss 0.02375536 - samples/sec: 161.02 - lr: 0.000001\n",
            "2023-01-02 06:16:41,079 epoch 6 - iter 6/11 - loss 0.02365659 - samples/sec: 168.03 - lr: 0.000001\n",
            "2023-01-02 06:16:41,272 epoch 6 - iter 7/11 - loss 0.02346403 - samples/sec: 172.88 - lr: 0.000001\n",
            "2023-01-02 06:16:41,521 epoch 6 - iter 8/11 - loss 0.02328595 - samples/sec: 132.74 - lr: 0.000001\n",
            "2023-01-02 06:16:41,775 epoch 6 - iter 9/11 - loss 0.02320541 - samples/sec: 130.40 - lr: 0.000001\n",
            "2023-01-02 06:16:42,058 epoch 6 - iter 10/11 - loss 0.02325377 - samples/sec: 116.55 - lr: 0.000001\n",
            "2023-01-02 06:16:42,262 epoch 6 - iter 11/11 - loss 0.02373296 - samples/sec: 162.64 - lr: 0.000001\n",
            "2023-01-02 06:16:42,265 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:42,269 EPOCH 6 done: loss 0.0237 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:42,369 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:42,384 DEV : loss 0.03195177763700485 - f1-score (micro avg)  0.8974\n",
            "2023-01-02 06:16:42,397 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:42,399 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:44,141 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:44,489 epoch 7 - iter 1/11 - loss 0.02077607 - samples/sec: 94.72 - lr: 0.000001\n",
            "2023-01-02 06:16:44,710 epoch 7 - iter 2/11 - loss 0.02166717 - samples/sec: 151.08 - lr: 0.000001\n",
            "2023-01-02 06:16:44,930 epoch 7 - iter 3/11 - loss 0.02167204 - samples/sec: 151.56 - lr: 0.000001\n",
            "2023-01-02 06:16:45,569 epoch 7 - iter 4/11 - loss 0.02180412 - samples/sec: 50.91 - lr: 0.000001\n",
            "2023-01-02 06:16:45,800 epoch 7 - iter 5/11 - loss 0.02197992 - samples/sec: 143.55 - lr: 0.000001\n",
            "2023-01-02 06:16:46,071 epoch 7 - iter 6/11 - loss 0.02213547 - samples/sec: 121.68 - lr: 0.000001\n",
            "2023-01-02 06:16:46,285 epoch 7 - iter 7/11 - loss 0.02211042 - samples/sec: 155.52 - lr: 0.000001\n",
            "2023-01-02 06:16:46,503 epoch 7 - iter 8/11 - loss 0.02222287 - samples/sec: 152.10 - lr: 0.000001\n",
            "2023-01-02 06:16:46,714 epoch 7 - iter 9/11 - loss 0.02237397 - samples/sec: 157.61 - lr: 0.000001\n",
            "2023-01-02 06:16:46,967 epoch 7 - iter 10/11 - loss 0.02237875 - samples/sec: 131.24 - lr: 0.000001\n",
            "2023-01-02 06:16:47,197 epoch 7 - iter 11/11 - loss 0.02248050 - samples/sec: 144.60 - lr: 0.000001\n",
            "2023-01-02 06:16:47,201 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:47,203 EPOCH 7 done: loss 0.0225 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:47,296 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:47,310 DEV : loss 0.030080299824476242 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:16:47,321 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:47,322 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:49,204 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:49,920 epoch 8 - iter 1/11 - loss 0.02064914 - samples/sec: 45.47 - lr: 0.000001\n",
            "2023-01-02 06:16:50,147 epoch 8 - iter 2/11 - loss 0.02078340 - samples/sec: 146.63 - lr: 0.000001\n",
            "2023-01-02 06:16:50,341 epoch 8 - iter 3/11 - loss 0.02109717 - samples/sec: 172.17 - lr: 0.000001\n",
            "2023-01-02 06:16:50,595 epoch 8 - iter 4/11 - loss 0.02144166 - samples/sec: 130.13 - lr: 0.000001\n",
            "2023-01-02 06:16:50,818 epoch 8 - iter 5/11 - loss 0.02205704 - samples/sec: 148.71 - lr: 0.000001\n",
            "2023-01-02 06:16:51,073 epoch 8 - iter 6/11 - loss 0.02203595 - samples/sec: 129.24 - lr: 0.000001\n",
            "2023-01-02 06:16:51,318 epoch 8 - iter 7/11 - loss 0.02194998 - samples/sec: 135.60 - lr: 0.000001\n",
            "2023-01-02 06:16:51,514 epoch 8 - iter 8/11 - loss 0.02166955 - samples/sec: 169.89 - lr: 0.000001\n",
            "2023-01-02 06:16:51,718 epoch 8 - iter 9/11 - loss 0.02213922 - samples/sec: 162.60 - lr: 0.000001\n",
            "2023-01-02 06:16:51,917 epoch 8 - iter 10/11 - loss 0.02181469 - samples/sec: 167.56 - lr: 0.000001\n",
            "2023-01-02 06:16:52,162 epoch 8 - iter 11/11 - loss 0.02199165 - samples/sec: 135.22 - lr: 0.000001\n",
            "2023-01-02 06:16:52,167 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:52,170 EPOCH 8 done: loss 0.0220 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:52,264 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:52,274 DEV : loss 0.02827140875160694 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:16:52,283 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:52,286 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:52,545 epoch 9 - iter 1/11 - loss 0.02072925 - samples/sec: 129.53 - lr: 0.000001\n",
            "2023-01-02 06:16:52,737 epoch 9 - iter 2/11 - loss 0.02125158 - samples/sec: 176.62 - lr: 0.000001\n",
            "2023-01-02 06:16:53,001 epoch 9 - iter 3/11 - loss 0.02050594 - samples/sec: 125.13 - lr: 0.000001\n",
            "2023-01-02 06:16:53,198 epoch 9 - iter 4/11 - loss 0.02131092 - samples/sec: 168.70 - lr: 0.000001\n",
            "2023-01-02 06:16:53,430 epoch 9 - iter 5/11 - loss 0.02112567 - samples/sec: 143.78 - lr: 0.000001\n",
            "2023-01-02 06:16:53,683 epoch 9 - iter 6/11 - loss 0.02076514 - samples/sec: 131.32 - lr: 0.000001\n",
            "2023-01-02 06:16:53,913 epoch 9 - iter 7/11 - loss 0.02029027 - samples/sec: 145.74 - lr: 0.000001\n",
            "2023-01-02 06:16:54,155 epoch 9 - iter 8/11 - loss 0.02043234 - samples/sec: 137.60 - lr: 0.000001\n",
            "2023-01-02 06:16:54,387 epoch 9 - iter 9/11 - loss 0.02007143 - samples/sec: 142.39 - lr: 0.000001\n",
            "2023-01-02 06:16:54,636 epoch 9 - iter 10/11 - loss 0.01986380 - samples/sec: 132.99 - lr: 0.000001\n",
            "2023-01-02 06:16:55,197 epoch 9 - iter 11/11 - loss 0.02038864 - samples/sec: 57.94 - lr: 0.000001\n",
            "2023-01-02 06:16:55,200 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:55,203 EPOCH 9 done: loss 0.0204 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:55,299 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:55,311 DEV : loss 0.026557443663477898 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:16:55,321 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:55,322 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:55,538 epoch 10 - iter 1/11 - loss 0.02186779 - samples/sec: 155.67 - lr: 0.000001\n",
            "2023-01-02 06:16:55,781 epoch 10 - iter 2/11 - loss 0.02128224 - samples/sec: 135.95 - lr: 0.000001\n",
            "2023-01-02 06:16:56,018 epoch 10 - iter 3/11 - loss 0.02063309 - samples/sec: 140.06 - lr: 0.000001\n",
            "2023-01-02 06:16:56,230 epoch 10 - iter 4/11 - loss 0.02127080 - samples/sec: 157.18 - lr: 0.000001\n",
            "2023-01-02 06:16:56,444 epoch 10 - iter 5/11 - loss 0.02096703 - samples/sec: 155.97 - lr: 0.000001\n",
            "2023-01-02 06:16:56,711 epoch 10 - iter 6/11 - loss 0.02105451 - samples/sec: 124.23 - lr: 0.000001\n",
            "2023-01-02 06:16:56,959 epoch 10 - iter 7/11 - loss 0.02071576 - samples/sec: 133.42 - lr: 0.000001\n",
            "2023-01-02 06:16:57,605 epoch 10 - iter 8/11 - loss 0.02045297 - samples/sec: 50.35 - lr: 0.000001\n",
            "2023-01-02 06:16:57,858 epoch 10 - iter 9/11 - loss 0.02037713 - samples/sec: 130.48 - lr: 0.000001\n",
            "2023-01-02 06:16:58,113 epoch 10 - iter 10/11 - loss 0.02011282 - samples/sec: 130.31 - lr: 0.000001\n",
            "2023-01-02 06:16:58,318 epoch 10 - iter 11/11 - loss 0.02026998 - samples/sec: 163.18 - lr: 0.000001\n",
            "2023-01-02 06:16:58,321 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:16:58,325 EPOCH 10 done: loss 0.0203 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 24.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:58,418 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:16:58,430 DEV : loss 0.024827666580677032 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:16:58,439 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:16:58,440 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:16:58,669 epoch 11 - iter 1/11 - loss 0.02040754 - samples/sec: 146.46 - lr: 0.000001\n",
            "2023-01-02 06:16:58,888 epoch 11 - iter 2/11 - loss 0.01859869 - samples/sec: 151.24 - lr: 0.000001\n",
            "2023-01-02 06:16:59,142 epoch 11 - iter 3/11 - loss 0.01899439 - samples/sec: 130.99 - lr: 0.000001\n",
            "2023-01-02 06:16:59,352 epoch 11 - iter 4/11 - loss 0.01903778 - samples/sec: 159.16 - lr: 0.000001\n",
            "2023-01-02 06:16:59,621 epoch 11 - iter 5/11 - loss 0.01947457 - samples/sec: 122.87 - lr: 0.000001\n",
            "2023-01-02 06:16:59,806 epoch 11 - iter 6/11 - loss 0.01977927 - samples/sec: 179.80 - lr: 0.000001\n",
            "2023-01-02 06:17:00,065 epoch 11 - iter 7/11 - loss 0.01973662 - samples/sec: 127.88 - lr: 0.000001\n",
            "2023-01-02 06:17:00,312 epoch 11 - iter 8/11 - loss 0.01929715 - samples/sec: 135.14 - lr: 0.000001\n",
            "2023-01-02 06:17:00,543 epoch 11 - iter 9/11 - loss 0.01903277 - samples/sec: 144.23 - lr: 0.000001\n",
            "2023-01-02 06:17:01,187 epoch 11 - iter 10/11 - loss 0.01910678 - samples/sec: 50.42 - lr: 0.000001\n",
            "2023-01-02 06:17:01,355 epoch 11 - iter 11/11 - loss 0.01934248 - samples/sec: 198.31 - lr: 0.000001\n",
            "2023-01-02 06:17:01,359 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:01,361 EPOCH 11 done: loss 0.0193 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:01,458 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:01,471 DEV : loss 0.023293551057577133 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:17:01,481 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:01,483 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:01,719 epoch 12 - iter 1/11 - loss 0.01525586 - samples/sec: 141.93 - lr: 0.000001\n",
            "2023-01-02 06:17:01,919 epoch 12 - iter 2/11 - loss 0.01631583 - samples/sec: 166.67 - lr: 0.000001\n",
            "2023-01-02 06:17:02,559 epoch 12 - iter 3/11 - loss 0.01775332 - samples/sec: 50.70 - lr: 0.000001\n",
            "2023-01-02 06:17:02,790 epoch 12 - iter 4/11 - loss 0.01777714 - samples/sec: 144.12 - lr: 0.000001\n",
            "2023-01-02 06:17:03,025 epoch 12 - iter 5/11 - loss 0.01836456 - samples/sec: 142.17 - lr: 0.000001\n",
            "2023-01-02 06:17:03,211 epoch 12 - iter 6/11 - loss 0.01842600 - samples/sec: 180.64 - lr: 0.000001\n",
            "2023-01-02 06:17:03,418 epoch 12 - iter 7/11 - loss 0.01875475 - samples/sec: 161.64 - lr: 0.000001\n",
            "2023-01-02 06:17:03,678 epoch 12 - iter 8/11 - loss 0.01862965 - samples/sec: 127.03 - lr: 0.000001\n",
            "2023-01-02 06:17:03,927 epoch 12 - iter 9/11 - loss 0.01863949 - samples/sec: 133.25 - lr: 0.000001\n",
            "2023-01-02 06:17:04,191 epoch 12 - iter 10/11 - loss 0.01866140 - samples/sec: 125.14 - lr: 0.000001\n",
            "2023-01-02 06:17:04,422 epoch 12 - iter 11/11 - loss 0.01874953 - samples/sec: 144.02 - lr: 0.000001\n",
            "2023-01-02 06:17:04,425 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:04,430 EPOCH 12 done: loss 0.0187 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:04,521 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:04,532 DEV : loss 0.02173517644405365 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:17:04,541 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:04,544 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:04,767 epoch 13 - iter 1/11 - loss 0.01886494 - samples/sec: 148.66 - lr: 0.000001\n",
            "2023-01-02 06:17:05,014 epoch 13 - iter 2/11 - loss 0.01651389 - samples/sec: 134.39 - lr: 0.000001\n",
            "2023-01-02 06:17:05,194 epoch 13 - iter 3/11 - loss 0.01768129 - samples/sec: 184.25 - lr: 0.000001\n",
            "2023-01-02 06:17:05,381 epoch 13 - iter 4/11 - loss 0.01783668 - samples/sec: 178.24 - lr: 0.000001\n",
            "2023-01-02 06:17:05,600 epoch 13 - iter 5/11 - loss 0.01792527 - samples/sec: 151.74 - lr: 0.000001\n",
            "2023-01-02 06:17:05,828 epoch 13 - iter 6/11 - loss 0.01774277 - samples/sec: 145.66 - lr: 0.000001\n",
            "2023-01-02 06:17:06,079 epoch 13 - iter 7/11 - loss 0.01809593 - samples/sec: 131.74 - lr: 0.000001\n",
            "2023-01-02 06:17:06,281 epoch 13 - iter 8/11 - loss 0.01808472 - samples/sec: 164.80 - lr: 0.000001\n",
            "2023-01-02 06:17:06,542 epoch 13 - iter 9/11 - loss 0.01814413 - samples/sec: 127.70 - lr: 0.000001\n",
            "2023-01-02 06:17:07,190 epoch 13 - iter 10/11 - loss 0.01819014 - samples/sec: 50.03 - lr: 0.000001\n",
            "2023-01-02 06:17:07,437 epoch 13 - iter 11/11 - loss 0.01819167 - samples/sec: 134.71 - lr: 0.000001\n",
            "2023-01-02 06:17:07,440 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:07,443 EPOCH 13 done: loss 0.0182 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:07,537 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:07,547 DEV : loss 0.02025836519896984 - f1-score (micro avg)  0.9487\n",
            "2023-01-02 06:17:07,556 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:07,557 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:07,768 epoch 14 - iter 1/11 - loss 0.01446296 - samples/sec: 160.55 - lr: 0.000001\n",
            "2023-01-02 06:17:07,995 epoch 14 - iter 2/11 - loss 0.01501851 - samples/sec: 145.27 - lr: 0.000001\n",
            "2023-01-02 06:17:08,212 epoch 14 - iter 3/11 - loss 0.01589922 - samples/sec: 152.91 - lr: 0.000001\n",
            "2023-01-02 06:17:08,487 epoch 14 - iter 4/11 - loss 0.01544673 - samples/sec: 120.80 - lr: 0.000001\n",
            "2023-01-02 06:17:08,751 epoch 14 - iter 5/11 - loss 0.01578462 - samples/sec: 125.45 - lr: 0.000001\n",
            "2023-01-02 06:17:08,962 epoch 14 - iter 6/11 - loss 0.01639730 - samples/sec: 156.65 - lr: 0.000001\n",
            "2023-01-02 06:17:09,161 epoch 14 - iter 7/11 - loss 0.01658227 - samples/sec: 168.30 - lr: 0.000001\n",
            "2023-01-02 06:17:09,373 epoch 14 - iter 8/11 - loss 0.01680817 - samples/sec: 156.57 - lr: 0.000001\n",
            "2023-01-02 06:17:09,597 epoch 14 - iter 9/11 - loss 0.01680823 - samples/sec: 148.42 - lr: 0.000001\n",
            "2023-01-02 06:17:09,836 epoch 14 - iter 10/11 - loss 0.01710404 - samples/sec: 139.11 - lr: 0.000001\n",
            "2023-01-02 06:17:10,414 epoch 14 - iter 11/11 - loss 0.01696359 - samples/sec: 56.27 - lr: 0.000001\n",
            "2023-01-02 06:17:10,418 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:10,420 EPOCH 14 done: loss 0.0170 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:10,514 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:10,526 DEV : loss 0.01888488419353962 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:10,535 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:10,537 saving best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:12,426 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:12,769 epoch 15 - iter 1/11 - loss 0.01567290 - samples/sec: 96.46 - lr: 0.000001\n",
            "2023-01-02 06:17:13,020 epoch 15 - iter 2/11 - loss 0.01725491 - samples/sec: 131.98 - lr: 0.000001\n",
            "2023-01-02 06:17:13,665 epoch 15 - iter 3/11 - loss 0.01638306 - samples/sec: 50.37 - lr: 0.000001\n",
            "2023-01-02 06:17:13,888 epoch 15 - iter 4/11 - loss 0.01666592 - samples/sec: 149.15 - lr: 0.000001\n",
            "2023-01-02 06:17:14,105 epoch 15 - iter 5/11 - loss 0.01683157 - samples/sec: 153.79 - lr: 0.000001\n",
            "2023-01-02 06:17:14,330 epoch 15 - iter 6/11 - loss 0.01640715 - samples/sec: 147.50 - lr: 0.000001\n",
            "2023-01-02 06:17:14,533 epoch 15 - iter 7/11 - loss 0.01665376 - samples/sec: 163.18 - lr: 0.000001\n",
            "2023-01-02 06:17:14,800 epoch 15 - iter 8/11 - loss 0.01652190 - samples/sec: 124.77 - lr: 0.000001\n",
            "2023-01-02 06:17:15,059 epoch 15 - iter 9/11 - loss 0.01649746 - samples/sec: 127.32 - lr: 0.000001\n",
            "2023-01-02 06:17:15,253 epoch 15 - iter 10/11 - loss 0.01648990 - samples/sec: 171.71 - lr: 0.000001\n",
            "2023-01-02 06:17:15,474 epoch 15 - iter 11/11 - loss 0.01640471 - samples/sec: 149.73 - lr: 0.000001\n",
            "2023-01-02 06:17:15,477 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:15,481 EPOCH 15 done: loss 0.0164 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:15,573 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:15,583 DEV : loss 0.017552679404616356 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:15,592 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:15,593 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:15,863 epoch 16 - iter 1/11 - loss 0.01321395 - samples/sec: 124.05 - lr: 0.000001\n",
            "2023-01-02 06:17:16,082 epoch 16 - iter 2/11 - loss 0.01460123 - samples/sec: 151.69 - lr: 0.000001\n",
            "2023-01-02 06:17:16,289 epoch 16 - iter 3/11 - loss 0.01489780 - samples/sec: 160.08 - lr: 0.000001\n",
            "2023-01-02 06:17:16,516 epoch 16 - iter 4/11 - loss 0.01530538 - samples/sec: 146.09 - lr: 0.000001\n",
            "2023-01-02 06:17:16,777 epoch 16 - iter 5/11 - loss 0.01564776 - samples/sec: 126.55 - lr: 0.000001\n",
            "2023-01-02 06:17:17,409 epoch 16 - iter 6/11 - loss 0.01559666 - samples/sec: 51.38 - lr: 0.000001\n",
            "2023-01-02 06:17:17,669 epoch 16 - iter 7/11 - loss 0.01591118 - samples/sec: 127.45 - lr: 0.000001\n",
            "2023-01-02 06:17:17,901 epoch 16 - iter 8/11 - loss 0.01563765 - samples/sec: 142.82 - lr: 0.000001\n",
            "2023-01-02 06:17:18,114 epoch 16 - iter 9/11 - loss 0.01612956 - samples/sec: 155.82 - lr: 0.000001\n",
            "2023-01-02 06:17:18,334 epoch 16 - iter 10/11 - loss 0.01612770 - samples/sec: 151.21 - lr: 0.000001\n",
            "2023-01-02 06:17:18,535 epoch 16 - iter 11/11 - loss 0.01629318 - samples/sec: 165.77 - lr: 0.000001\n",
            "2023-01-02 06:17:18,538 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:18,541 EPOCH 16 done: loss 0.0163 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:18,645 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:18,654 DEV : loss 0.016510242596268654 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:18,663 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:18,664 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:18,886 epoch 17 - iter 1/11 - loss 0.01237454 - samples/sec: 151.47 - lr: 0.000001\n",
            "2023-01-02 06:17:19,118 epoch 17 - iter 2/11 - loss 0.01419418 - samples/sec: 142.56 - lr: 0.000001\n",
            "2023-01-02 06:17:19,350 epoch 17 - iter 3/11 - loss 0.01489430 - samples/sec: 142.73 - lr: 0.000001\n",
            "2023-01-02 06:17:19,617 epoch 17 - iter 4/11 - loss 0.01492226 - samples/sec: 124.16 - lr: 0.000001\n",
            "2023-01-02 06:17:20,253 epoch 17 - iter 5/11 - loss 0.01460504 - samples/sec: 51.09 - lr: 0.000001\n",
            "2023-01-02 06:17:20,499 epoch 17 - iter 6/11 - loss 0.01511896 - samples/sec: 134.34 - lr: 0.000001\n",
            "2023-01-02 06:17:20,781 epoch 17 - iter 7/11 - loss 0.01458419 - samples/sec: 117.37 - lr: 0.000001\n",
            "2023-01-02 06:17:21,009 epoch 17 - iter 8/11 - loss 0.01421643 - samples/sec: 146.11 - lr: 0.000001\n",
            "2023-01-02 06:17:21,210 epoch 17 - iter 9/11 - loss 0.01450731 - samples/sec: 165.73 - lr: 0.000001\n",
            "2023-01-02 06:17:21,409 epoch 17 - iter 10/11 - loss 0.01512541 - samples/sec: 167.58 - lr: 0.000001\n",
            "2023-01-02 06:17:21,626 epoch 17 - iter 11/11 - loss 0.01543031 - samples/sec: 152.21 - lr: 0.000001\n",
            "2023-01-02 06:17:21,628 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:21,632 EPOCH 17 done: loss 0.0154 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:21,728 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:21,739 DEV : loss 0.01549516897648573 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:21,748 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:21,749 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:21,963 epoch 18 - iter 1/11 - loss 0.01498811 - samples/sec: 156.24 - lr: 0.000001\n",
            "2023-01-02 06:17:22,616 epoch 18 - iter 2/11 - loss 0.01475933 - samples/sec: 49.88 - lr: 0.000001\n",
            "2023-01-02 06:17:22,840 epoch 18 - iter 3/11 - loss 0.01435720 - samples/sec: 148.85 - lr: 0.000001\n",
            "2023-01-02 06:17:23,058 epoch 18 - iter 4/11 - loss 0.01388295 - samples/sec: 154.17 - lr: 0.000001\n",
            "2023-01-02 06:17:23,250 epoch 18 - iter 5/11 - loss 0.01343110 - samples/sec: 174.01 - lr: 0.000001\n",
            "2023-01-02 06:17:23,506 epoch 18 - iter 6/11 - loss 0.01405597 - samples/sec: 129.78 - lr: 0.000001\n",
            "2023-01-02 06:17:23,779 epoch 18 - iter 7/11 - loss 0.01389495 - samples/sec: 121.65 - lr: 0.000001\n",
            "2023-01-02 06:17:24,011 epoch 18 - iter 8/11 - loss 0.01404436 - samples/sec: 144.09 - lr: 0.000001\n",
            "2023-01-02 06:17:24,203 epoch 18 - iter 9/11 - loss 0.01450832 - samples/sec: 173.41 - lr: 0.000001\n",
            "2023-01-02 06:17:24,425 epoch 18 - iter 10/11 - loss 0.01481733 - samples/sec: 151.02 - lr: 0.000001\n",
            "2023-01-02 06:17:24,644 epoch 18 - iter 11/11 - loss 0.01487608 - samples/sec: 151.72 - lr: 0.000001\n",
            "2023-01-02 06:17:24,647 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:24,649 EPOCH 18 done: loss 0.0149 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:24,751 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:24,763 DEV : loss 0.0144841643050313 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:24,775 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:24,776 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:24,962 epoch 19 - iter 1/11 - loss 0.01450425 - samples/sec: 180.93 - lr: 0.000001\n",
            "2023-01-02 06:17:25,219 epoch 19 - iter 2/11 - loss 0.01509607 - samples/sec: 128.48 - lr: 0.000001\n",
            "2023-01-02 06:17:25,487 epoch 19 - iter 3/11 - loss 0.01481535 - samples/sec: 123.57 - lr: 0.000001\n",
            "2023-01-02 06:17:25,742 epoch 19 - iter 4/11 - loss 0.01470131 - samples/sec: 130.42 - lr: 0.000001\n",
            "2023-01-02 06:17:26,007 epoch 19 - iter 5/11 - loss 0.01505948 - samples/sec: 124.94 - lr: 0.000001\n",
            "2023-01-02 06:17:26,660 epoch 19 - iter 6/11 - loss 0.01436067 - samples/sec: 49.86 - lr: 0.000001\n",
            "2023-01-02 06:17:26,890 epoch 19 - iter 7/11 - loss 0.01433646 - samples/sec: 145.09 - lr: 0.000001\n",
            "2023-01-02 06:17:27,115 epoch 19 - iter 8/11 - loss 0.01437333 - samples/sec: 147.33 - lr: 0.000001\n",
            "2023-01-02 06:17:27,352 epoch 19 - iter 9/11 - loss 0.01481230 - samples/sec: 140.04 - lr: 0.000001\n",
            "2023-01-02 06:17:27,590 epoch 19 - iter 10/11 - loss 0.01490379 - samples/sec: 140.00 - lr: 0.000001\n",
            "2023-01-02 06:17:27,815 epoch 19 - iter 11/11 - loss 0.01520601 - samples/sec: 148.13 - lr: 0.000001\n",
            "2023-01-02 06:17:27,818 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:27,820 EPOCH 19 done: loss 0.0152 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:27,918 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:27,928 DEV : loss 0.013508237898349762 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:27,939 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:27,941 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:28,590 epoch 20 - iter 1/11 - loss 0.01814879 - samples/sec: 50.22 - lr: 0.000001\n",
            "2023-01-02 06:17:28,834 epoch 20 - iter 2/11 - loss 0.01632563 - samples/sec: 136.06 - lr: 0.000001\n",
            "2023-01-02 06:17:29,049 epoch 20 - iter 3/11 - loss 0.01423446 - samples/sec: 155.38 - lr: 0.000001\n",
            "2023-01-02 06:17:29,247 epoch 20 - iter 4/11 - loss 0.01362282 - samples/sec: 168.06 - lr: 0.000001\n",
            "2023-01-02 06:17:29,434 epoch 20 - iter 5/11 - loss 0.01405408 - samples/sec: 178.14 - lr: 0.000001\n",
            "2023-01-02 06:17:29,619 epoch 20 - iter 6/11 - loss 0.01390292 - samples/sec: 179.70 - lr: 0.000001\n",
            "2023-01-02 06:17:29,833 epoch 20 - iter 7/11 - loss 0.01383092 - samples/sec: 156.44 - lr: 0.000001\n",
            "2023-01-02 06:17:30,094 epoch 20 - iter 8/11 - loss 0.01381681 - samples/sec: 127.67 - lr: 0.000001\n",
            "2023-01-02 06:17:30,304 epoch 20 - iter 9/11 - loss 0.01389545 - samples/sec: 158.64 - lr: 0.000001\n",
            "2023-01-02 06:17:30,555 epoch 20 - iter 10/11 - loss 0.01380765 - samples/sec: 131.68 - lr: 0.000001\n",
            "2023-01-02 06:17:30,754 epoch 20 - iter 11/11 - loss 0.01424225 - samples/sec: 166.96 - lr: 0.000001\n",
            "2023-01-02 06:17:30,757 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:30,759 EPOCH 20 done: loss 0.0142 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:30,865 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:30,877 DEV : loss 0.012749857269227505 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:30,886 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:30,888 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:31,161 epoch 21 - iter 1/11 - loss 0.01310178 - samples/sec: 122.19 - lr: 0.000001\n",
            "2023-01-02 06:17:31,369 epoch 21 - iter 2/11 - loss 0.01425046 - samples/sec: 160.50 - lr: 0.000001\n",
            "2023-01-02 06:17:31,559 epoch 21 - iter 3/11 - loss 0.01356446 - samples/sec: 175.82 - lr: 0.000001\n",
            "2023-01-02 06:17:31,791 epoch 21 - iter 4/11 - loss 0.01346496 - samples/sec: 143.96 - lr: 0.000001\n",
            "2023-01-02 06:17:32,012 epoch 21 - iter 5/11 - loss 0.01284502 - samples/sec: 150.82 - lr: 0.000001\n",
            "2023-01-02 06:17:32,213 epoch 21 - iter 6/11 - loss 0.01307929 - samples/sec: 167.07 - lr: 0.000001\n",
            "2023-01-02 06:17:32,471 epoch 21 - iter 7/11 - loss 0.01362003 - samples/sec: 128.72 - lr: 0.000001\n",
            "2023-01-02 06:17:32,682 epoch 21 - iter 8/11 - loss 0.01370843 - samples/sec: 157.85 - lr: 0.000001\n",
            "2023-01-02 06:17:33,336 epoch 21 - iter 9/11 - loss 0.01333620 - samples/sec: 49.63 - lr: 0.000001\n",
            "2023-01-02 06:17:33,568 epoch 21 - iter 10/11 - loss 0.01352899 - samples/sec: 143.65 - lr: 0.000001\n",
            "2023-01-02 06:17:33,798 epoch 21 - iter 11/11 - loss 0.01370908 - samples/sec: 144.43 - lr: 0.000001\n",
            "2023-01-02 06:17:33,802 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:33,806 EPOCH 21 done: loss 0.0137 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:33,902 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:33,918 DEV : loss 0.01214172039180994 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:33,928 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:33,930 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:34,200 epoch 22 - iter 1/11 - loss 0.01286309 - samples/sec: 122.63 - lr: 0.000001\n",
            "2023-01-02 06:17:34,517 epoch 22 - iter 2/11 - loss 0.01458783 - samples/sec: 104.45 - lr: 0.000001\n",
            "2023-01-02 06:17:34,756 epoch 22 - iter 3/11 - loss 0.01447976 - samples/sec: 139.98 - lr: 0.000001\n",
            "2023-01-02 06:17:35,041 epoch 22 - iter 4/11 - loss 0.01342394 - samples/sec: 118.45 - lr: 0.000001\n",
            "2023-01-02 06:17:35,319 epoch 22 - iter 5/11 - loss 0.01333000 - samples/sec: 119.88 - lr: 0.000001\n",
            "2023-01-02 06:17:36,016 epoch 22 - iter 6/11 - loss 0.01366514 - samples/sec: 46.79 - lr: 0.000001\n",
            "2023-01-02 06:17:36,329 epoch 22 - iter 7/11 - loss 0.01384901 - samples/sec: 106.01 - lr: 0.000001\n",
            "2023-01-02 06:17:36,538 epoch 22 - iter 8/11 - loss 0.01403023 - samples/sec: 161.69 - lr: 0.000001\n",
            "2023-01-02 06:17:36,826 epoch 22 - iter 9/11 - loss 0.01407663 - samples/sec: 116.68 - lr: 0.000001\n",
            "2023-01-02 06:17:37,109 epoch 22 - iter 10/11 - loss 0.01397567 - samples/sec: 120.78 - lr: 0.000001\n",
            "2023-01-02 06:17:37,329 epoch 22 - iter 11/11 - loss 0.01386593 - samples/sec: 154.41 - lr: 0.000001\n",
            "2023-01-02 06:17:37,336 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:37,338 EPOCH 22 done: loss 0.0139 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 15.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:37,477 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:37,489 DEV : loss 0.01159027498215437 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:37,502 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:37,504 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:37,709 epoch 23 - iter 1/11 - loss 0.01525807 - samples/sec: 163.41 - lr: 0.000001\n",
            "2023-01-02 06:17:38,357 epoch 23 - iter 2/11 - loss 0.01219652 - samples/sec: 50.10 - lr: 0.000001\n",
            "2023-01-02 06:17:38,581 epoch 23 - iter 3/11 - loss 0.01160086 - samples/sec: 149.47 - lr: 0.000001\n",
            "2023-01-02 06:17:38,800 epoch 23 - iter 4/11 - loss 0.01267782 - samples/sec: 151.19 - lr: 0.000001\n",
            "2023-01-02 06:17:39,040 epoch 23 - iter 5/11 - loss 0.01208552 - samples/sec: 139.11 - lr: 0.000001\n",
            "2023-01-02 06:17:39,303 epoch 23 - iter 6/11 - loss 0.01195913 - samples/sec: 125.33 - lr: 0.000001\n",
            "2023-01-02 06:17:39,552 epoch 23 - iter 7/11 - loss 0.01228731 - samples/sec: 132.96 - lr: 0.000001\n",
            "2023-01-02 06:17:39,776 epoch 23 - iter 8/11 - loss 0.01249046 - samples/sec: 149.15 - lr: 0.000001\n",
            "2023-01-02 06:17:40,029 epoch 23 - iter 9/11 - loss 0.01221453 - samples/sec: 131.34 - lr: 0.000001\n",
            "2023-01-02 06:17:40,293 epoch 23 - iter 10/11 - loss 0.01247785 - samples/sec: 124.97 - lr: 0.000001\n",
            "2023-01-02 06:17:40,477 epoch 23 - iter 11/11 - loss 0.01308566 - samples/sec: 181.64 - lr: 0.000001\n",
            "2023-01-02 06:17:40,480 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:40,483 EPOCH 23 done: loss 0.0131 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:40,577 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:40,590 DEV : loss 0.011029730550944805 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:40,599 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:40,600 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:40,826 epoch 24 - iter 1/11 - loss 0.01429229 - samples/sec: 148.30 - lr: 0.000001\n",
            "2023-01-02 06:17:41,078 epoch 24 - iter 2/11 - loss 0.01317152 - samples/sec: 131.32 - lr: 0.000001\n",
            "2023-01-02 06:17:41,332 epoch 24 - iter 3/11 - loss 0.01169648 - samples/sec: 130.75 - lr: 0.000001\n",
            "2023-01-02 06:17:41,581 epoch 24 - iter 4/11 - loss 0.01268935 - samples/sec: 133.78 - lr: 0.000001\n",
            "2023-01-02 06:17:41,852 epoch 24 - iter 5/11 - loss 0.01278086 - samples/sec: 122.31 - lr: 0.000001\n",
            "2023-01-02 06:17:42,095 epoch 24 - iter 6/11 - loss 0.01230411 - samples/sec: 136.40 - lr: 0.000001\n",
            "2023-01-02 06:17:42,304 epoch 24 - iter 7/11 - loss 0.01283935 - samples/sec: 159.48 - lr: 0.000001\n",
            "2023-01-02 06:17:42,519 epoch 24 - iter 8/11 - loss 0.01269155 - samples/sec: 154.60 - lr: 0.000001\n",
            "2023-01-02 06:17:43,171 epoch 24 - iter 9/11 - loss 0.01280892 - samples/sec: 50.28 - lr: 0.000001\n",
            "2023-01-02 06:17:43,402 epoch 24 - iter 10/11 - loss 0.01257059 - samples/sec: 144.31 - lr: 0.000001\n",
            "2023-01-02 06:17:43,581 epoch 24 - iter 11/11 - loss 0.01264170 - samples/sec: 185.51 - lr: 0.000001\n",
            "2023-01-02 06:17:43,586 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:43,588 EPOCH 24 done: loss 0.0126 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:43,685 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:43,694 DEV : loss 0.010571947321295738 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:43,704 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:43,705 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:43,890 epoch 25 - iter 1/11 - loss 0.01239524 - samples/sec: 181.80 - lr: 0.000001\n",
            "2023-01-02 06:17:44,162 epoch 25 - iter 2/11 - loss 0.01186315 - samples/sec: 121.67 - lr: 0.000001\n",
            "2023-01-02 06:17:44,370 epoch 25 - iter 3/11 - loss 0.01208633 - samples/sec: 160.35 - lr: 0.000001\n",
            "2023-01-02 06:17:44,591 epoch 25 - iter 4/11 - loss 0.01166595 - samples/sec: 150.74 - lr: 0.000001\n",
            "2023-01-02 06:17:44,848 epoch 25 - iter 5/11 - loss 0.01185865 - samples/sec: 128.97 - lr: 0.000001\n",
            "2023-01-02 06:17:45,053 epoch 25 - iter 6/11 - loss 0.01148382 - samples/sec: 162.74 - lr: 0.000001\n",
            "2023-01-02 06:17:45,321 epoch 25 - iter 7/11 - loss 0.01190369 - samples/sec: 124.01 - lr: 0.000001\n",
            "2023-01-02 06:17:45,556 epoch 25 - iter 8/11 - loss 0.01235217 - samples/sec: 141.15 - lr: 0.000001\n",
            "2023-01-02 06:17:46,200 epoch 25 - iter 9/11 - loss 0.01213618 - samples/sec: 50.51 - lr: 0.000001\n",
            "2023-01-02 06:17:46,400 epoch 25 - iter 10/11 - loss 0.01260542 - samples/sec: 167.44 - lr: 0.000001\n",
            "2023-01-02 06:17:46,591 epoch 25 - iter 11/11 - loss 0.01266738 - samples/sec: 174.29 - lr: 0.000001\n",
            "2023-01-02 06:17:46,594 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:46,598 EPOCH 25 done: loss 0.0127 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:46,694 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:46,707 DEV : loss 0.010136761702597141 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:46,718 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:46,719 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:46,939 epoch 26 - iter 1/11 - loss 0.01378689 - samples/sec: 152.70 - lr: 0.000001\n",
            "2023-01-02 06:17:47,201 epoch 26 - iter 2/11 - loss 0.01185212 - samples/sec: 127.23 - lr: 0.000001\n",
            "2023-01-02 06:17:47,481 epoch 26 - iter 3/11 - loss 0.01085041 - samples/sec: 117.75 - lr: 0.000001\n",
            "2023-01-02 06:17:48,128 epoch 26 - iter 4/11 - loss 0.01060897 - samples/sec: 50.22 - lr: 0.000001\n",
            "2023-01-02 06:17:48,383 epoch 26 - iter 5/11 - loss 0.01024331 - samples/sec: 130.13 - lr: 0.000001\n",
            "2023-01-02 06:17:48,606 epoch 26 - iter 6/11 - loss 0.01122147 - samples/sec: 149.29 - lr: 0.000001\n",
            "2023-01-02 06:17:48,826 epoch 26 - iter 7/11 - loss 0.01120005 - samples/sec: 152.27 - lr: 0.000001\n",
            "2023-01-02 06:17:49,053 epoch 26 - iter 8/11 - loss 0.01124996 - samples/sec: 146.17 - lr: 0.000001\n",
            "2023-01-02 06:17:49,304 epoch 26 - iter 9/11 - loss 0.01163295 - samples/sec: 132.27 - lr: 0.000001\n",
            "2023-01-02 06:17:49,526 epoch 26 - iter 10/11 - loss 0.01162470 - samples/sec: 151.00 - lr: 0.000001\n",
            "2023-01-02 06:17:49,723 epoch 26 - iter 11/11 - loss 0.01200131 - samples/sec: 169.59 - lr: 0.000001\n",
            "2023-01-02 06:17:49,726 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:49,730 EPOCH 26 done: loss 0.0120 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:49,827 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:49,839 DEV : loss 0.009760446846485138 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:49,849 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:49,851 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:50,507 epoch 27 - iter 1/11 - loss 0.00849149 - samples/sec: 49.68 - lr: 0.000001\n",
            "2023-01-02 06:17:50,709 epoch 27 - iter 2/11 - loss 0.00878253 - samples/sec: 166.00 - lr: 0.000001\n",
            "2023-01-02 06:17:50,962 epoch 27 - iter 3/11 - loss 0.00995086 - samples/sec: 131.34 - lr: 0.000001\n",
            "2023-01-02 06:17:51,189 epoch 27 - iter 4/11 - loss 0.01167429 - samples/sec: 146.59 - lr: 0.000001\n",
            "2023-01-02 06:17:51,400 epoch 27 - iter 5/11 - loss 0.01153331 - samples/sec: 157.01 - lr: 0.000001\n",
            "2023-01-02 06:17:51,613 epoch 27 - iter 6/11 - loss 0.01187649 - samples/sec: 156.71 - lr: 0.000001\n",
            "2023-01-02 06:17:51,866 epoch 27 - iter 7/11 - loss 0.01145569 - samples/sec: 131.22 - lr: 0.000001\n",
            "2023-01-02 06:17:52,139 epoch 27 - iter 8/11 - loss 0.01181464 - samples/sec: 121.64 - lr: 0.000001\n",
            "2023-01-02 06:17:52,356 epoch 27 - iter 9/11 - loss 0.01162405 - samples/sec: 152.99 - lr: 0.000001\n",
            "2023-01-02 06:17:52,561 epoch 27 - iter 10/11 - loss 0.01200670 - samples/sec: 162.97 - lr: 0.000001\n",
            "2023-01-02 06:17:52,758 epoch 27 - iter 11/11 - loss 0.01214245 - samples/sec: 168.67 - lr: 0.000001\n",
            "2023-01-02 06:17:52,761 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:52,765 EPOCH 27 done: loss 0.0121 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:52,865 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:52,880 DEV : loss 0.00940112303942442 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:52,889 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:52,891 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:53,119 epoch 28 - iter 1/11 - loss 0.01466083 - samples/sec: 148.56 - lr: 0.000001\n",
            "2023-01-02 06:17:53,388 epoch 28 - iter 2/11 - loss 0.01294638 - samples/sec: 122.70 - lr: 0.000001\n",
            "2023-01-02 06:17:53,581 epoch 28 - iter 3/11 - loss 0.01273757 - samples/sec: 172.79 - lr: 0.000001\n",
            "2023-01-02 06:17:53,847 epoch 28 - iter 4/11 - loss 0.01187757 - samples/sec: 125.88 - lr: 0.000001\n",
            "2023-01-02 06:17:54,080 epoch 28 - iter 5/11 - loss 0.01122096 - samples/sec: 142.95 - lr: 0.000001\n",
            "2023-01-02 06:17:54,350 epoch 28 - iter 6/11 - loss 0.01150163 - samples/sec: 123.00 - lr: 0.000001\n",
            "2023-01-02 06:17:54,566 epoch 28 - iter 7/11 - loss 0.01188799 - samples/sec: 153.81 - lr: 0.000001\n",
            "2023-01-02 06:17:55,210 epoch 28 - iter 8/11 - loss 0.01186464 - samples/sec: 50.46 - lr: 0.000001\n",
            "2023-01-02 06:17:55,412 epoch 28 - iter 9/11 - loss 0.01203070 - samples/sec: 165.16 - lr: 0.000001\n",
            "2023-01-02 06:17:55,618 epoch 28 - iter 10/11 - loss 0.01180694 - samples/sec: 161.79 - lr: 0.000001\n",
            "2023-01-02 06:17:55,808 epoch 28 - iter 11/11 - loss 0.01179831 - samples/sec: 175.66 - lr: 0.000001\n",
            "2023-01-02 06:17:55,811 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:55,814 EPOCH 28 done: loss 0.0118 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:55,916 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:55,925 DEV : loss 0.009090901352465153 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:55,935 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:55,938 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:56,199 epoch 29 - iter 1/11 - loss 0.00816220 - samples/sec: 128.04 - lr: 0.000001\n",
            "2023-01-02 06:17:56,470 epoch 29 - iter 2/11 - loss 0.00837280 - samples/sec: 123.61 - lr: 0.000001\n",
            "2023-01-02 06:17:56,669 epoch 29 - iter 3/11 - loss 0.00859217 - samples/sec: 166.96 - lr: 0.000001\n",
            "2023-01-02 06:17:57,321 epoch 29 - iter 4/11 - loss 0.00982290 - samples/sec: 49.98 - lr: 0.000001\n",
            "2023-01-02 06:17:57,528 epoch 29 - iter 5/11 - loss 0.00994171 - samples/sec: 160.65 - lr: 0.000001\n",
            "2023-01-02 06:17:57,793 epoch 29 - iter 6/11 - loss 0.01094280 - samples/sec: 125.33 - lr: 0.000001\n",
            "2023-01-02 06:17:58,015 epoch 29 - iter 7/11 - loss 0.01118681 - samples/sec: 149.53 - lr: 0.000001\n",
            "2023-01-02 06:17:58,226 epoch 29 - iter 8/11 - loss 0.01168691 - samples/sec: 157.97 - lr: 0.000001\n",
            "2023-01-02 06:17:58,458 epoch 29 - iter 9/11 - loss 0.01139817 - samples/sec: 144.09 - lr: 0.000001\n",
            "2023-01-02 06:17:58,672 epoch 29 - iter 10/11 - loss 0.01120150 - samples/sec: 155.31 - lr: 0.000001\n",
            "2023-01-02 06:17:58,901 epoch 29 - iter 11/11 - loss 0.01150386 - samples/sec: 145.53 - lr: 0.000001\n",
            "2023-01-02 06:17:58,905 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:17:58,909 EPOCH 29 done: loss 0.0115 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 22.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:59,007 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:17:59,021 DEV : loss 0.008832154795527458 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:17:59,032 BAD EPOCHS (no improvement): 0\n",
            "2023-01-02 06:17:59,034 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:17:59,253 epoch 30 - iter 1/11 - loss 0.01244930 - samples/sec: 153.99 - lr: 0.000001\n",
            "2023-01-02 06:17:59,508 epoch 30 - iter 2/11 - loss 0.01272514 - samples/sec: 131.58 - lr: 0.000001\n",
            "2023-01-02 06:17:59,763 epoch 30 - iter 3/11 - loss 0.01170527 - samples/sec: 130.32 - lr: 0.000001\n",
            "2023-01-02 06:18:00,024 epoch 30 - iter 4/11 - loss 0.01121860 - samples/sec: 126.86 - lr: 0.000001\n",
            "2023-01-02 06:18:00,237 epoch 30 - iter 5/11 - loss 0.01094651 - samples/sec: 155.85 - lr: 0.000001\n",
            "2023-01-02 06:18:00,488 epoch 30 - iter 6/11 - loss 0.01069754 - samples/sec: 132.99 - lr: 0.000001\n",
            "2023-01-02 06:18:00,679 epoch 30 - iter 7/11 - loss 0.01159281 - samples/sec: 175.43 - lr: 0.000001\n",
            "2023-01-02 06:18:01,338 epoch 30 - iter 8/11 - loss 0.01132357 - samples/sec: 49.48 - lr: 0.000001\n",
            "2023-01-02 06:18:01,568 epoch 30 - iter 9/11 - loss 0.01139269 - samples/sec: 144.76 - lr: 0.000001\n",
            "2023-01-02 06:18:01,801 epoch 30 - iter 10/11 - loss 0.01142767 - samples/sec: 142.93 - lr: 0.000001\n",
            "2023-01-02 06:18:02,031 epoch 30 - iter 11/11 - loss 0.01110647 - samples/sec: 144.19 - lr: 0.000001\n",
            "2023-01-02 06:18:02,034 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:18:02,037 EPOCH 30 done: loss 0.0111 - lr 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 23.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:18:02,129 Evaluating as a multi-label problem: False\n",
            "2023-01-02 06:18:02,144 DEV : loss 0.00859711691737175 - f1-score (micro avg)  0.9744\n",
            "2023-01-02 06:18:02,153 BAD EPOCHS (no improvement): 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:18:03,850 Test data not provided setting final score to 0\n",
            "2023-01-02 06:18:03,859 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:18:03,860 WARNING: No LOSS found for test split in this data.\n",
            "2023-01-02 06:18:03,865 Are you sure you want to plot LOSS and not another value?\n",
            "2023-01-02 06:18:03,870 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:18:03,893 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:18:03,894 WARNING: No F1 found for test split in this data.\n",
            "2023-01-02 06:18:03,898 Are you sure you want to plot F1 and not another value?\n",
            "2023-01-02 06:18:03,903 ----------------------------------------------------------------------------------------------------\n",
            "2023-01-02 06:18:05,625 Loss and F1 plots are saved in resources/taggers/sentiment/training.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-02 06:18:06,487 Weights plots are saved in resources/taggers/sentiment/weights.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# generate model and train it\n",
        "\n",
        "# 1. Create a corpus\n",
        "\"\"\"\n",
        "Corpus is like a vocabulary. It contains all the data available.\n",
        "It also splits the training dataset automatically into train and validation data.\n",
        "\"\"\"\n",
        "\n",
        "data_folder = \"/content/data\"\n",
        "column_name_map = {2 : \"text\",\n",
        "                   3 : \"label\"}\n",
        "label_type = \"class\"\n",
        "train_file = \"train.csv\"\n",
        "test_file = \"test.csv\"\n",
        "dev_file = None\n",
        "skip_header = True\n",
        "delimiter = ','\n",
        "quotechar = '\"'\n",
        "corpus : Corpus = CSVClassificationCorpus(data_folder=data_folder,\n",
        "                                          column_name_map=column_name_map,\n",
        "                                          label_type=label_type,\n",
        "                                          train_file=train_file,\n",
        "                                          test_file=test_file,\n",
        "                                          dev_file=dev_file,\n",
        "                                          skip_header=skip_header,\n",
        "                                          delimiter=delimiter,\n",
        "                                          quotechar=quotechar\n",
        "                                          )\n",
        "\n",
        "\n",
        "# 2. Create the label dictionary\n",
        "\"\"\"\n",
        "Label dictionary contains a mapping of labels to positive and negative samples in the dataset.\n",
        "\"\"\"\n",
        "\n",
        "label_dictionary = corpus.make_label_dictionary(label_type=label_type)\n",
        "\n",
        "\n",
        "# 3. Make a list of word embeddings\n",
        "\"\"\"\n",
        "Word embeddings are numerical representations of text. They capture the contextual neaning of each word.\n",
        "We are using the RoBERTa model pre-trained on twitter sentiment analysis dataset.\n",
        "\"\"\"\n",
        "\n",
        "word_embeddings = [TransformerWordEmbeddings('cardiffnlp/twitter-roberta-base-sentiment-latest')]\n",
        "\n",
        "\n",
        "# 4. Make document embeddings\n",
        "\"\"\"\n",
        "Document embeddings convert the word embeddings which are generated for each word into a single embedding for the entire document.\n",
        "This gives us a much denser representation of the document.\n",
        "\"\"\"\n",
        "\n",
        "hidden_size = 512\n",
        "reproject_words = True\n",
        "reproject_words_dimension = 256\n",
        "rnn_type = \"LSTM\"\n",
        "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(embeddings=word_embeddings,\n",
        "                                                                   hidden_size=hidden_size,\n",
        "                                                                   reproject_words=reproject_words,\n",
        "                                                                   reproject_words_dimension=reproject_words_dimension,\n",
        "                                                                   rnn_type=rnn_type\n",
        "                                                                   )        \n",
        "\n",
        "\n",
        "# 5. Create the text classifier\n",
        "\"\"\"\n",
        "This is the model we use for the classifcation of text. \n",
        "\"\"\"\n",
        "\n",
        "classifier = TextClassifier(document_embeddings=document_embeddings,\n",
        "                            label_dictionary=label_dictionary,\n",
        "                            label_type=label_type,\n",
        "                            multi_label=False\n",
        "                            )\n",
        "\n",
        "\n",
        "# 6. initialize the text classifier trainer\n",
        "\"\"\"\n",
        "We are using Flair's inbuilt trainer for training our model\n",
        "\"\"\"\n",
        "\n",
        "trainer = ModelTrainer(model=classifier, corpus=corpus)\n",
        "\n",
        "\n",
        "# 7. start the training\n",
        "\"\"\"\n",
        "We will use the AdamW optimizer and CosineAnnealingLR scheduler from PyTorch library for the best results\n",
        "\"\"\"\n",
        "\n",
        "learning_rate = 1e-6\n",
        "weight_decay = 0.1\n",
        "T_max = 30\n",
        "base_path = \"/content/FlairModel\"\n",
        "max_epochs = 30\n",
        "train_with_dev = False\n",
        "optimizer = AdamW(classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=T_max)\n",
        "trainer.train(base_path=base_path,\n",
        "              max_epochs=max_epochs,\n",
        "              train_with_dev=train_with_dev,\n",
        "              scheduler=scheduler,\n",
        "              optimizer=optimizer\n",
        "              )\n",
        "\n",
        "# 8. plot training curves (optional)\n",
        "\"\"\"\n",
        "Now we will plot the loss curves of train and test data to understand how good the model is.\n",
        "If the train loss keeps decreasing, but the validation loss decreases and increases it is a sign of overfitting.\n",
        "If the model overfits it cannot generalize well to new data.\n",
        "\"\"\"\n",
        "\n",
        "plotter = Plotter()\n",
        "plotter.plot_training_curves('/content/FlairModel/loss.tsv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use trained weights provided by us to load the model\n",
        "\n",
        "\n",
        "\n",
        "1.   Download the trained weights file, final-model.pt from the following \n",
        "[Google Drive Link](https://drive.google.com/file/d/1hUjDOIY8pGvfmPLQFx24kpDS9yZAFB1J/view?usp=share_link)\n",
        "2.   Create a directory called FlairModel in /content in Google Colab\n",
        "3.   Upload final-model.pt to the FlairModel directory\n",
        "4.   Run cells under \"Imports, download datasets, pre-process datasets\" for checking our model's accuracy\n",
        "5.   Move on to results to obtain inferences\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8FIZrxk5Eps3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results of the model:\n",
        "\n",
        "The loss curves indicate that the model has not overfit to the data and hence the model will be able to generalize well to new data.\n",
        "\n",
        "We achieve a validation F1 score of 0.9744 which is quite good. Some of the feedback sentences are quite ambiguous as to whether they are positive or negative. Hence expecting a machine learning model to classify them correctly is quite the long shot."
      ],
      "metadata": {
        "id": "YzMcXWWuhv5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the final model with the best fit for inference\n",
        "base_path = \"/content/FlairModel\"\n",
        "model_path = os.path.join(base_path, \"final-model.pt\")\n",
        "classifier = TextClassifier.load(model_path)"
      ],
      "metadata": {
        "id": "mLIkqJr0nN5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the train dataset\n",
        "\n",
        "# 1. Generate train sentences\n",
        "train_df=pd.read_csv(\"/content/data/train.csv\")\n",
        "train_sentences=train_df[\"text\"].apply(lambda x: Sentence(x))\n",
        "\n",
        "# 2. Generate predictions for the test sentences\n",
        "predictions = []\n",
        "for i in range(len(train_sentences)):\n",
        "    classifier.predict(train_sentences[i])\n",
        "    predictions.append(int(train_sentences[i].labels[0].value))\n",
        "train_df[\"prediction\"] = predictions\n",
        "\n",
        "# 3. Write the predictions to a .csv file\n",
        "train_df.to_csv(\"Train_Predictions_Without_Confidence_Score.csv\",index=False)\n",
        "\n",
        "# 4. Add the confidence score to the predictions for further analysis and write them to a .csv file\n",
        "scores = []\n",
        "for i in range(len(train_sentences)):\n",
        "    scores.append(train_sentences[i].score)\n",
        "train_df[\"sentiment_score\"] = scores\n",
        "\n",
        "train_df.to_csv(\"Train_Predictions_With_Confidence_Score.csv\",index=False)"
      ],
      "metadata": {
        "id": "sCOwFHCsnLE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the unlabelled test dataset\n",
        "\n",
        "# 1. Generate test sentences\n",
        "test_df=pd.read_csv(\"/content/data/test.csv\")\n",
        "test_sentences=test_df[\"Verbatim Feedback \"].apply(lambda x: Sentence(x))\n",
        "\n",
        "# 2. Generate predictions for the test sentences\n",
        "for i in range(len(test_sentences)):\n",
        "    classifier.predict(test_sentences[i])\n",
        "    test_df[\"Sentiment (1=Positive & 0= Negative)\"][i]=test_sentences[i].labels[0].value\n",
        "\n",
        "# 3. Write the predictions to a .csv file\n",
        "test_df.to_csv(\"Test_Predictions_Without_Confidence_Score.csv\",index=False)\n",
        "\n",
        "# 4. Add the confidence score to the predictions for further analysis and write them to a .csv file\n",
        "scores = []\n",
        "for i in range(len(test_sentences)):\n",
        "    scores.append(test_sentences[i].score)\n",
        "test_df[\"Sentiment_Score\"] = scores\n",
        "\n",
        "test_df.to_csv(\"Test_Predictions_With_Confidence_Score.csv\",index=False)"
      ],
      "metadata": {
        "id": "yEaV08A0Bqj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate performance metrics of the model on the entire training dataset\n",
        "\n",
        "def run_model_metrics(samples_df, prediction, target):\n",
        "    correct = 0\n",
        "    incorrect_index = []\n",
        "\n",
        "    true_n = 0\n",
        "    false_n = 0\n",
        "    true_p = 0\n",
        "    false_p = 0\n",
        "    for i in range(len(prediction)):\n",
        "        if(prediction[i]==1 and target[i]==1):\n",
        "            true_p += 1\n",
        "            correct += 1\n",
        "        elif(prediction[i]==1 and target[i]==0):\n",
        "            false_p += 1\n",
        "            incorrect_index.append(i)\n",
        "        elif(prediction[i]==0 and target[i]==1):\n",
        "            false_n += 1\n",
        "            incorrect_index.append(i)\n",
        "        elif(prediction[i]==0 and target[i]==0):\n",
        "            true_n += 1\n",
        "            correct += 1\n",
        "            \n",
        "    precision = (true_p) / (true_p + false_p)\n",
        "    recall = (true_p) / (true_p + false_n)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    accuracy = (correct/len(target)) * 100\n",
        "    print(f\"Number of samples classified correctly : {correct}\")\n",
        "    print(f\"Number of samples classified incorrectly : {len(target) - correct}\")\n",
        "    print(f\"Accuracy of model : {accuracy}\")\n",
        "    print(f\"F1 Score : {f1}\")\n",
        "    print(\"Incorrectly classified samples:\")\n",
        "    display(samples_df.iloc[incorrect_index])\n",
        "\n",
        "target = train_df[\"label\"].to_list()\n",
        "run_model_metrics(train_df, predictions, target)"
      ],
      "metadata": {
        "id": "xAXYKweppTTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To obtain inference on a new sentence"
      ],
      "metadata": {
        "id": "r2pFJK96Fgar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ADD FEEDBACK SENTENCE HERE\"\n",
        "sentence = Sentence(text)\n",
        "classifier.predict(sentence)\n",
        "prediction = sentence.labels[0].value\n",
        "confidence = sentence.score\n",
        "print(f\"{text} : {Prediction} with a confidence of {confidence}\")"
      ],
      "metadata": {
        "id": "BWo6wFWiFfYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U7pgKkxjFCtR",
        "C4PtJwBYE6N4"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}